<!doctype html><html lang=zh-CN data-theme-mode=auto><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><link rel=canonical href=https://blog.glowled.top/post/reinforcement-learning-base-quickpass/><title>强化学习基础-粗略过一遍 | GlowLED</title><meta name=description content="把强化学习的基础知识粗略地过了一遍，几乎无数学。但是还是不全。"><script>window.siteConfig=JSON.parse('{"anchor_icon":null,"base":"https://blog.glowled.top/","clipboard":{"copyright":{"count":50,"enable":false,"license_type":"by-nc-sa"},"fail":{"en":"Copy failed (ﾟ⊿ﾟ)ﾂ","ja":"コピー失敗 (ﾟ⊿ﾟ)ﾂ","zh-cn":"复制失败 (ﾟ⊿ﾟ)ﾂ","zh-tw":"複製失敗 (ﾟ⊿ﾟ)ﾂ"},"success":{"en":"Copy successfully (*^▽^*)","ja":"コピー成功 (*^▽^*)","zh-cn":"复制成功 (*^▽^*)","zh-tw":"複製成功 (*^▽^*)"}},"code_block":{"expand":true},"icon_font":"4552607_0khxww3tj3q9","outdate":{"daysago":180,"enable":true,"message":{"en":"This article was last updated on {time}. Please note that the content may no longer be applicable.","ja":"この記事は最終更新日：{time}。記載内容が現在有効でない可能性がありますのでご注意ください。","zh-cn":"本文最后更新于 {time}，请注意文中内容可能已不适用。","zh-tw":"本文最後更新於 {time}，請注意文中內容可能已不適用。"}}}')</script><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css?family=Mulish:400,400italic,700,700italic%7cNoto%20Serif%20SC:400,400italic,700,700italic%7c&amp;display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Mulish:400,400italic,700,700italic%7cNoto%20Serif%20SC:400,400italic,700,700italic%7c&amp;display=swap" media=print onload='this.media="all"'><link rel=preload href=//at.alicdn.com/t/c/font_4552607_0khxww3tj3q9.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=stylesheet href=https://blog.glowled.top/css/loader.css><meta property="og:type" content="website"><meta property="og:title" content="强化学习基础-粗略过一遍 | GlowLED"><meta property="og:description" content="把强化学习的基础知识粗略地过了一遍，几乎无数学。但是还是不全。"><meta property="og:url" content="https://blog.glowled.top/post/reinforcement-learning-base-quickpass/"><meta property="og:site_name" content="GlowLED的后花园"><meta property="og:image" content="/"><meta property="article:author" content="GlowLED"><meta property="article:published_time" content="2026-01-28T14:42:14+08:00"><meta property="article:modified_time" content="2026-01-28T14:42:14+08:00"><meta property="article:tag" content="技术"><meta name=twitter:card content="summary"><meta name=twitter:url content="https://blog.glowled.top/post/reinforcement-learning-base-quickpass/"><meta name=twitter:title content="强化学习基础-粗略过一遍 | GlowLED"><meta name=twitter:description content="把强化学习的基础知识粗略地过了一遍，几乎无数学。但是还是不全。"><meta name=twitter:image content="/"><link rel="shortcut icon" href=https://blog.glowled.top/favicon.ico><link rel=stylesheet href=https://blog.glowled.top/css/main.css><link rel=preload as=style href=https://npm.webcache.cn/photoswipe@5.4.4/dist/photoswipe.css integrity=sha384-IfxC36XL/toUyJ939C73PcgMuRzAZuIzZxE38drsmO5p6jD7ei+Zx/1oA/0l8ysE crossorigin=anonymous onload='this.onload=null,this.rel="stylesheet"'><link rel=preload as=style href=https://npm.webcache.cn/katex@0.16.22/dist/katex.min.css integrity=sha384-5TcZemv2l/9On385z///+d7MSYlvIEw9FuZTIdZ14vJLqWphw7e7ZPuOiCHJcFCP crossorigin=anonymous onload='this.onload=null,this.rel="stylesheet"'><script src=https://npm.webcache.cn/pace-js@1.2.4/pace.min.js integrity=sha384-k6YtvFUEIuEFBdrLKJ3YAUbBki333tj1CSUisai5Cswsg9wcLNaPzsTHDswp4Az8 crossorigin=anonymous></script><link rel=stylesheet href=https://npm.webcache.cn/@reimujs/aos@0.1.0/dist/aos.css integrity=sha384-4NN3fZ5AokFyHuoihl7A9qWaCt+HsAtOaUsXwJGRb4/SMBtFr2vcNSHR5E8dg0Wk crossorigin=anonymous></head><body><div id=loader><div class="loading-left-bg loading-bg"></div><div class="loading-right-bg loading-bg"></div><div class=spinner-box><div class="loading-taichi rotate"><svg width="150" height="150" viewBox="0 0 1024 1024" class="icon" shape-rendering="geometricPrecision"><path d="M303.5 432a80 80 0 01-12 160 80 80 0 0112-160z" fill="var(--red-1, #ff5252)"/><path d="M512 65a447 447 0 010 894V929a417 417 0 000-834 417 417 0 000 834v30a447 447 0 010-894zm0 30A417 417 0 01929 512 208.5 208.5.0 01720.5 720.5V592a80 80 0 000-160 80 80 0 000 160V720.5A208.5 208.5.0 01512 512 208.5 208.5.0 00303.5 303.5 208.5 208.5.0 0095 512 417 417 0 01512 95z" fill="var(--red-1, #ff5252)"/></svg></div><div class=loading-word>正在打开封印...</div></div></div></div><script>var time=null,startLoading=()=>{time=Date.now(),document.getElementById("loader").classList.remove("loading")},endLoading=()=>{time?Date.now()-time>500?(time=null,document.body.style.overflow="auto",document.getElementById("loader").classList.add("loading")):(setTimeout(endLoading,500-(Date.now()-time)),time=null):(document.body.style.overflow="auto",document.getElementById("loader").classList.add("loading"))};window.addEventListener("DOMContentLoaded",endLoading),document.getElementById("loader").addEventListener("click",endLoading)</script><div id=copy-tooltip style="pointer-events:none;opacity:0;transition:all .2s ease;position:fixed;top:50%;left:50%;z-index:999;transform:translate(-50%,-50%);color:#fff;background:rgba(0,0,0,.5);padding:10px 15px;border-radius:10px"></div><div id=lang-tooltip style="pointer-events:none;opacity:0;transition:all .2s ease;position:fixed;top:50%;left:50%;z-index:999;transform:translate(-50%,-50%);color:#fff;background:rgba(0,0,0,.5);padding:10px 15px;border-radius:10px">本文章没有找到对应的语言版本</div><div id=container><div id=wrap><div id=header-nav><nav id=main-nav><span class=main-nav-link-wrap><div class='main-nav-icon icon'>&#xe632;</div><a class=main-nav-link href=https://blog.glowled.top/>首页</a>
</span><span class=main-nav-link-wrap><div class='main-nav-icon icon'>&#xe633;</div><a class=main-nav-link href=https://blog.glowled.top/archives>归档</a>
</span><span class=main-nav-link-wrap><div class='main-nav-icon icon'>&#xe628;</div><a class=main-nav-link href=https://blog.glowled.top/about>关于</a>
</span><span class=main-nav-link-wrap><div class='main-nav-icon icon'>&#xe639;</div><a class=main-nav-link href=https://blog.glowled.top/friend>友链</a>
</span><a id=main-nav-toggle class=nav-icon></a></nav><nav id=sub-nav><a id=nav-search-btn class="nav-icon popup-trigger" title=搜索></a></nav></div><header id=header><picture></picture><img fetchpriority=high src=https://blog.glowled.top/images/banner_yanami.jpg alt=强化学习基础-粗略过一遍><div id=header-outer><div id=header-title><a href=https://blog.glowled.top/ id=logo><h1 data-aos=slide-up>强化学习基础-粗略过一遍</h1></a><h2 id=subtitle-wrap data-aos=slide-down></h2></div></div></header><div id=content class=sidebar-left><aside id=sidebar><div class="sidebar-wrapper wrap-sticky"><div class=sidebar-wrap data-aos=fade-up><div class=sidebar-toc-sidebar><div class=sidebar-toc><h3 class=toc-title>文章目录</h3><div class="sidebar-toc-wrapper toc-div-class"><nav id=TableOfContents><ul><li><a href=#基本概念>基本概念</a><ul><li><a href=#场景描述>场景描述</a></li><li><a href=#公理化>公理化</a></li></ul></li><li><a href=#算法分类>算法分类</a><ul><li><a href=#model-free-与-model-based>Model-Free 与 Model-Based</a></li><li><a href=#on-policy-与-off-policy>On-Policy 与 Off-Policy</a></li><li><a href=#policy-based-与-value-based>Policy-Based 与 Value-Based</a></li></ul></li><li><a href=#经典算法>经典算法</a><ul><li><a href=#q-learning>Q-learning</a></li><li><a href=#deep-q-network-dqn>Deep Q Network (DQN)</a></li><li><a href=#policy-gradient>Policy Gradient</a></li><li><a href=#actor-critic>Actor Critic</a></li></ul></li></ul></nav></div></div></div><div class="sidebar-common-sidebar hidden"><div class=sidebar-author><img data-src=https://blog.glowled.top/avatar/avatar_yamada.jpg data-sizes=auto alt=GlowLED class=lazyload><div class=sidebar-author-name>GlowLED</div><div class=sidebar-description>一个混吃等死的普通人</div></div><div class=sidebar-state><div class=sidebar-state-article><div>文章</div><div class=sidebar-state-number>6</div></div><div class=sidebar-state-category><div>分类</div><div class=sidebar-state-number>3</div></div><div class=sidebar-state-tag><div>标签</div><div class=sidebar-state-number>3</div></div></div><div class=sidebar-social><div class="icon-bilibili sidebar-social-icon"><a href="https://space.bilibili.com/514211707?spm_id_from=333.1007.0.0" itemprop=url target=_blank aria-label=bilibili rel="noopener external nofollow noreferrer"></a></div><div class="icon-github sidebar-social-icon"><a href=https://github.com/GlowLED itemprop=url target=_blank aria-label=github rel="noopener external nofollow noreferrer"></a></div><div class="icon-steam sidebar-social-icon"><a href=https://steamcommunity.com/profiles/76561199712499779/ itemprop=url target=_blank aria-label=steam rel="noopener external nofollow noreferrer"></a></div><div class="icon-zhihu sidebar-social-icon"><a href=https://www.zhihu.com/people/glowled-89 itemprop=url target=_blank aria-label=zhihu rel="noopener external nofollow noreferrer"></a></div></div><div class=sidebar-menu><div class=sidebar-menu-link-wrap><a class=sidebar-menu-link-dummy href=https://blog.glowled.top/ aria-label=首页></a><div class='sidebar-menu-icon icon'>&#xe632;</div><div class=sidebar-menu-link>首页</div></div><div class=sidebar-menu-link-wrap><a class=sidebar-menu-link-dummy href=https://blog.glowled.top/archives aria-label=归档></a><div class='sidebar-menu-icon icon'>&#xe633;</div><div class=sidebar-menu-link>归档</div></div><div class=sidebar-menu-link-wrap><a class=sidebar-menu-link-dummy href=https://blog.glowled.top/about aria-label=关于></a><div class='sidebar-menu-icon icon'>&#xe628;</div><div class=sidebar-menu-link>关于</div></div><div class=sidebar-menu-link-wrap><a class=sidebar-menu-link-dummy href=https://blog.glowled.top/friend aria-label=友链></a><div class='sidebar-menu-icon icon'>&#xe639;</div><div class=sidebar-menu-link>友链</div></div></div></div><div class=sidebar-btn-wrapper style=position:static><div class="sidebar-toc-btn current"></div><div class=sidebar-common-btn></div></div></div></div><div class=sidebar-widget></div></aside><section id=main><article class="h-entry article" itemprop=blogPost itemscope itemtype=https://schema.org/BlogPosting><div class=article-inner data-aos=fade-up><div class=article-meta><div class=article-date><span class=article-date-link data-aos=zoom-in><time datetime="2026-01-28 14:42:14 +0800 +0800" itemprop=datePublished>2026-01-28</time>
<time style=display:none id=post-update-time>2026-01-28</time></span></div><div class=article-category><a class=article-category-link href=https://blog.glowled.top/categories/%e5%bc%ba%e5%8c%96%e5%ad%a6%e4%b9%a0 data-aos=zoom-in>强化学习</a><a class=article-category-link href=https://blog.glowled.top/categories/%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0 data-aos=zoom-in>深度学习</a></div></div><div class=hr-line></div><div class="e-content article-entry" itemprop=articleBody><blockquote id=outdate-blockquote style=display:none><p></p></blockquote><h2 id=基本概念><a class=header-anchor href=#%e5%9f%ba%e6%9c%ac%e6%a6%82%e5%bf%b5></a>基本概念</h2><h3 id=场景描述><a class=header-anchor href=#%e5%9c%ba%e6%99%af%e6%8f%8f%e8%bf%b0></a>场景描述</h3><ul><li><p>Environment: 环境. 是一个外部系统, 智能体处于这个系统中，能够感知到这个系统并且能够基于感知到的状态做出一定的行动。</p></li><li><p>state/observation: 状态/观测. 状态反映了世界的全部信息, 观测是状态的子集.</p></li><li><p>agent: 智能体. 做出决策的个体.</p></li><li><p>action: 动作. 不同的环境允许不同种类的动作，在给定的环境中，有效动作的集合经常被称为动作空间(action space)，包括离散动作空间(discrete action spaces)和连续动作空间(continuous action spaces).</p></li><li><p>reward: 奖励. 是由环境给的一个标量的反馈信号(scalar feedback signal).</p></li></ul><p>强化学习设想中, agent在environment中行动, 在某时刻获取observation, 采取action并促使environment做出改变. 在某些时刻可以获取reward. 强化学习的目标是使得reward总和最大化.</p><h3 id=公理化><a class=header-anchor href=#%e5%85%ac%e7%90%86%e5%8c%96></a>公理化</h3><p>动作使用$ a $表示, 状态(观测)使用$ s $表示, 时刻使用$ t $表示.</p><ol><li><p><strong>Policy</strong>: 策略. 用于决定下一步做出什么行动.</p><p>如果是确定性的, 一般用$ \mu $表示:</p></li></ol>$$
a_t=\mu(s_t)
$$<p>​ 如果是随机性的, 一般用$ \pi $表示:</p>$$
a_t \sim \pi(\cdot|s_t)
$$<ol start=2><li><strong>State Transition</strong>: 状态转移. 可以是确定的也可以是随机的. 一般认为是随机的. 可以用<strong>状态密度函数</strong>来表示:</li></ol>$$
p(s'|s, a) = \mathbb{P}(S'=s'|S=s, A=a)
$$<ol start=3><li><p><strong>Return</strong>: 回报. 又称<strong>cumulated future reward</strong>, 一般表示为$ U $, 定义为:</p>$$
U_t=R_t+R_{t+1}+R_{t+2}+R_{t+3}+\cdots
$$<p>其中$ R_t $为第$ t $时刻的奖励. $ U $即未来和当下所有奖励之和.</p><p>有时候我们认为未来的奖励不如现在等值的奖励那么好, 所以我们会乘以一个discount rate $ \gamma $. $ \gamma \in (0, 1]$. $ U $被扩展为:</p>$$
U=R_t + \gamma R_{t+1} + \gamma^2R_{t+2}+\gamma^3R_{t+3} + \cdots
$$</li><li><p><strong>Value Function</strong>: 价值函数.</p><p>价值函数使用期望对未来的收益进行预测，一方面不必等待未来的收益实际发生就可以获知当前状态的好坏，另一方面通过期望汇总了未来各种可能的收益情况。使用价值函数可以很方便地评价不同策略的好坏。</p></li><li><p><strong>State-value Function</strong>: 状态价值函数. 用于度量给定策略下, 某个状态的回报的期望. 用于评判状态的好坏.</p></li><li><p><strong>Action-value Function</strong>: 行动价值函数. 用于度量给定策略和状态下, 采取某个行动的回报的期望. 用于评判动作的好坏.</p></li></ol><h2 id=算法分类><a class=header-anchor href=#%e7%ae%97%e6%b3%95%e5%88%86%e7%b1%bb></a>算法分类</h2><h3 id=model-free-与-model-based><a class=header-anchor href=#model-free-%e4%b8%8e-model-based></a>Model-Free 与 Model-Based</h3><p>按照环境是否已知来划分的.</p><p>Model-Free就是不去学习与理解环境, 环境给出什么信息就是什么信息, 常见的方法有Policy Optimization和Q-learning.</p><p>Model-Based是去学习和理解环境，学会用一个模型来模拟环境，通过模拟的环境来得到反馈。Model-Based相当于比Model-Free多了模拟环境这个环节，通过模拟环境预判接下来会发生的所有情况，然后选择最佳的情况。</p><p>可以认为这里的Model指的是"对环境的建模".</p><h3 id=on-policy-与-off-policy><a class=header-anchor href=#on-policy-%e4%b8%8e-off-policy></a>On-Policy 与 Off-Policy</h3><p>On-Policy指策略必须运行才能优化. 即策略必须在环境中做决策, 一边决策一边优化.</p><p>Off-Policy指策略是在场下优化的. 是先在环境中采样大量动作-状态-奖励序列, 然后再优化. 所以Off-Policy可以根据其它策略的序列进行优化.</p><h3 id=policy-based-与-value-based><a class=header-anchor href=#policy-based-%e4%b8%8e-value-based></a>Policy-Based 与 Value-Based</h3><p>Policy-Based中, 动作从策略中采样得到. 即策略产生每个动作的概率, 然后agent采样这个概率分布, 获取当前应该执行的动作.</p><p>Value-Based中, 策略生成每个动作的价值. agent每次总是选择最高价值的动作.</p><p>这两者是可以结合的.</p><h2 id=经典算法><a class=header-anchor href=#%e7%bb%8f%e5%85%b8%e7%ae%97%e6%b3%95></a>经典算法</h2><h3 id=q-learning><a class=header-anchor href=#q-learning></a>Q-learning</h3><p>在Q-learning中，我们维护一张Q-table，表的维数为：状态数S * 动作数A，表中每个数代表在当前状态S下可以采用动作A可以获得的未来收益的折现和。</p><p>例如:</p><table><thead><tr><th style=text-align:center>状态\动作</th><th style=text-align:center>action1</th><th style=text-align:center>action2</th><th style=text-align:center>action3</th><th style=text-align:center>action4</th></tr></thead><tbody><tr><td style=text-align:center>state1</td><td style=text-align:center>$ Q_{11} $</td><td style=text-align:center>$ Q_{12} $</td><td style=text-align:center>$ Q_{13} $</td><td style=text-align:center>$ Q_{14} $</td></tr><tr><td style=text-align:center>state2</td><td style=text-align:center>$ Q_{21} $</td><td style=text-align:center>$ Q_{22} $</td><td style=text-align:center>$ Q_{23} $</td><td style=text-align:center>$ Q_{24} $</td></tr><tr><td style=text-align:center>state3</td><td style=text-align:center>$ Q_{31} $</td><td style=text-align:center>$ Q_{32} $</td><td style=text-align:center>$ Q_{33} $</td><td style=text-align:center>$ Q_{34} $</td></tr></tbody></table><p>当我们的agent位于state1时, 它会选择四个动作中对应回报期望最大的那个行动. 这可以认为是行动价值函数.</p><p>Q函数就是这样一个行动价值函数. 它有两个输入: &ldquo;状态"和"动作&rdquo;.</p>$$
Q^{\pi}(s_t, a_t) = E[R_{t+1}+\gamma R_{t+2} +\gamma^2 R_{t+3} + \cdots | s_t, a_t]
$$<p>我们可以把Q函数视为一个在Q-Table上滚动的读取器，用于寻找与当前状态关联的行以及与动作关联的列。它会从相匹配的单元格中返回 Q 值。这就是未来奖励的期望。</p><p>在我们探索之前, Q-table会被设置成一个设定值(通常是0). 在对环境的探索过程中, Q-table的值会通过<strong>Bellman方程</strong>迭代式更新, 以给出对$ Q(s, a) $越来越好的近似.</p><p><img src=https://pic4.zhimg.com/v2-bc3517d0e73e145d525d9542e58b35e3_1440w.jpg alt=zhihu上的图></p><h3 id=deep-q-network-dqn><a class=header-anchor href=#deep-q-network-dqn></a>Deep Q Network (DQN)</h3><p>Q-table的维护需要满足: 1. 动作与状态空间是离散的, 如果是连续的, 则需要想办法离散化. 2. 动作和状态空间最好别太大, 特别是面对无限的空间时, 需要想办法有限化.</p><p>就算是采用离散化和有限化, Q-table的维护依然很麻烦. 问题复杂时, 项数实在太多了.</p><p>这时候一个很显然的思路是使用一个参数化的函数来表示Q-table. 而神经网络就很符合要求.</p><p><img src=https://pica.zhimg.com/v2-cec53729a7c798c93012c478d8086596_1440w.jpg alt=zhihu上的图></p><p>Q-table表示的Q函数, 需要提供state与action两项来检索. 而在DeepQLearning中, 我们用神经网络表示的Q函数只需要提供state, 返回的是所有action的Q值. 即返回原先Q-table中的一行.</p><blockquote><p>这么做我想是因为神经网络最后一层输出不能太小. 如果像Q-table那样只输出一个值, 最后一层就太小了, 效率很低. 而且同时预测所有动作, 有利于网络更泛化地优化.</p></blockquote><p>Q-learning与DQN都是off-policy的. 行为策略(如$ \epsilon $-greedy策略)与目标策略(用于评估和优化Q值的策略)是分离的. Q函数可以从过去任何策略产生的经验中学习(经验回放).</p><p>神经网络学习中, 一般来说, 目标是固定的. 而DQN中, Q是由Bellman方程计算得到, 是一个动态规划过程. 所以我们会让Q在一段实践内保持不变, 让神经网络更易于学习.</p><h3 id=policy-gradient><a class=header-anchor href=#policy-gradient></a>Policy Gradient</h3><p>Q-learning与DQN都是基于价值的. 即学习的核心是对于动作价值的评估, 而根据价值采取行动则是简单的.</p><p>Policy Gradient是基于策略的. 大道至简, 输入状态, 输出为每个动作的概率, 即输出动作的分布, agent直接从分布中采样动作(或者直接采取概率最大的动作).</p><p><img src=https://pica.zhimg.com/v2-1a8a4baf9752a489ced36a2d31e17d34_1440w.jpg alt=zhihu上的图></p><blockquote><p>不过这样的话, 价值函数是隐式的, 比较难得到&mldr;</p></blockquote><h3 id=actor-critic><a class=header-anchor href=#actor-critic></a>Actor Critic</h3><p>Actor-Critic是Policy Based与Value Based的结合.</p><p>Actor指的是$ \pi_\theta (a | s) $, 即带参数$ \theta $的策略$ \pi $. Critic指的是值函数$ V^\pi(s) $, 对当前策略的值函数进行估计, 即评价策略的好坏. 即"在当前状态下, 采取策略$ \pi $, 我得到的回报的期望是多少?".</p><p>训练时, 同时训练这两个. 但其实我们最需要的是Actor. 所以本质上来说, Actor Critic算法是Policy Based的.</p></div><footer class=article-footer><ul class=article-tag-list itemprop=keywords><li class=article-tag-list-item data-aos=zoom-in><a class=article-tag-list-link href=https://blog.glowled.top/tags/%e6%8a%80%e6%9c%af rel=tag>技术</a></li></ul></footer></div><nav id=article-nav data-aos=fade-up><div class="article-nav-link-wrap article-nav-link-left"><img data-src=https://api.mtyqx.cn/tapi/random.php data-sizes=auto alt=体渲染-随笔 class=lazyload><a href=https://blog.glowled.top/post/volume-rendering/></a><div class=article-nav-caption>前一篇</div><h3 class=article-nav-title>体渲染-随笔</h3></div><div class="article-nav-link-wrap article-nav-link-right"><img data-src=https://t.alcy.cc/lai data-sizes=auto alt="Deep Q Network (DQN)笔记" class=lazyload><a href=https://blog.glowled.top/post/deep-q-network/></a><div class=article-nav-caption>后一篇</div><h3 class=article-nav-title>Deep Q Network (DQN)笔记</h3></div></nav></article><section id=comments data-aos=fade-up><div class=comment-header><h2 class=comment-title>欢迎友好讨论~</h2><div class=comment-selector><div class=comment-selector-wrap><div class=selector-item data-selector=giscus><span>giscus</span></div></div></div></div><div class=comment-content><div class="comment giscus-comment" data-aos=fade-up></div></div></section></section></div><footer id=footer><div style=width:100%;overflow:hidden><div class=footer-line></div></div><div id=footer-info><div><span class=icon-copyright></span>2025-2026<span class="footer-info-sep rotate"></span>
GlowLED</div><div>基于&nbsp;<a href=https://gohugo.io/ target=_blank>Hugo</a>&nbsp; Theme.<a href=https://github.com/D-Sketon/hugo-theme-reimu target=_blank>Reimu</a></div><div><span class=icon-brush>&nbsp;13.8k</span>
&nbsp;|&nbsp;
<span class=icon-coffee>&nbsp;01:10</span></div><div><span class=icon-eye></span>
<span id=busuanzi_container_site_pv>总访问量&nbsp;<span id=busuanzi_value_site_pv></span></span>
&nbsp;|&nbsp;
<span class=icon-user></span>
<span id=busuanzi_container_site_uv>总访客量&nbsp;<span id=busuanzi_value_site_uv></span></span></div></div></footer><div class=sidebar-top><div class="sidebar-top-taichi rotate"></div><div class=arrow-up></div></div><div id=mask class=hide></div></div><nav id=mobile-nav><div class=sidebar-wrap><div class=sidebar-toc-sidebar><div class=sidebar-toc><h3 class=toc-title>文章目录</h3><div class="sidebar-toc-wrapper toc-div-class"><nav id=TableOfContents><ul><li><a href=#基本概念>基本概念</a><ul><li><a href=#场景描述>场景描述</a></li><li><a href=#公理化>公理化</a></li></ul></li><li><a href=#算法分类>算法分类</a><ul><li><a href=#model-free-与-model-based>Model-Free 与 Model-Based</a></li><li><a href=#on-policy-与-off-policy>On-Policy 与 Off-Policy</a></li><li><a href=#policy-based-与-value-based>Policy-Based 与 Value-Based</a></li></ul></li><li><a href=#经典算法>经典算法</a><ul><li><a href=#q-learning>Q-learning</a></li><li><a href=#deep-q-network-dqn>Deep Q Network (DQN)</a></li><li><a href=#policy-gradient>Policy Gradient</a></li><li><a href=#actor-critic>Actor Critic</a></li></ul></li></ul></nav></div></div></div><div class="sidebar-common-sidebar hidden"><div class=sidebar-author><img data-src=https://blog.glowled.top/avatar/avatar_yamada.jpg data-sizes=auto alt=GlowLED class=lazyload><div class=sidebar-author-name>GlowLED</div><div class=sidebar-description>一个混吃等死的普通人</div></div><div class=sidebar-state><div class=sidebar-state-article><div>文章</div><div class=sidebar-state-number>6</div></div><div class=sidebar-state-category><div>分类</div><div class=sidebar-state-number>3</div></div><div class=sidebar-state-tag><div>标签</div><div class=sidebar-state-number>3</div></div></div><div class=sidebar-social><div class="icon-bilibili sidebar-social-icon"><a href="https://space.bilibili.com/514211707?spm_id_from=333.1007.0.0" itemprop=url target=_blank aria-label=bilibili rel="noopener external nofollow noreferrer"></a></div><div class="icon-github sidebar-social-icon"><a href=https://github.com/GlowLED itemprop=url target=_blank aria-label=github rel="noopener external nofollow noreferrer"></a></div><div class="icon-steam sidebar-social-icon"><a href=https://steamcommunity.com/profiles/76561199712499779/ itemprop=url target=_blank aria-label=steam rel="noopener external nofollow noreferrer"></a></div><div class="icon-zhihu sidebar-social-icon"><a href=https://www.zhihu.com/people/glowled-89 itemprop=url target=_blank aria-label=zhihu rel="noopener external nofollow noreferrer"></a></div></div><div class=sidebar-menu><div class=sidebar-menu-link-wrap><a class=sidebar-menu-link-dummy href=https://blog.glowled.top/ aria-label=首页></a><div class='sidebar-menu-icon icon'>&#xe632;</div><div class=sidebar-menu-link>首页</div></div><div class=sidebar-menu-link-wrap><a class=sidebar-menu-link-dummy href=https://blog.glowled.top/archives aria-label=归档></a><div class='sidebar-menu-icon icon'>&#xe633;</div><div class=sidebar-menu-link>归档</div></div><div class=sidebar-menu-link-wrap><a class=sidebar-menu-link-dummy href=https://blog.glowled.top/about aria-label=关于></a><div class='sidebar-menu-icon icon'>&#xe628;</div><div class=sidebar-menu-link>关于</div></div><div class=sidebar-menu-link-wrap><a class=sidebar-menu-link-dummy href=https://blog.glowled.top/friend aria-label=友链></a><div class='sidebar-menu-icon icon'>&#xe639;</div><div class=sidebar-menu-link>友链</div></div></div></div></div><div class=sidebar-btn-wrapper><div class="sidebar-toc-btn current"></div><div class=sidebar-common-btn></div></div></nav></div><div class=site-search><div class="reimu-popup popup"><div class=reimu-search><div class=reimu-search-input-icon></div><div class=reimu-search-input id=reimu-search-input></div><div class=popup-btn-close></div></div><div class=reimu-results><div id=reimu-stats></div><div id=reimu-hits></div><div id=reimu-pagination class=reimu-pagination></div></div><img class=reimu-bg src=https://blog.glowled.top/images/ATRI.jpg></div></div><script src=https://npm.webcache.cn/lazysizes@5.3.2/lazysizes.min.js integrity=sha384-3gT/vsepWkfz/ff7PpWNUeMzeWoH3cDhm/A8jM7ouoAK0/fP/9bcHHR5kHq2nf+e crossorigin=anonymous></script><script src=https://npm.webcache.cn/clipboard@2.0.11/dist/clipboard.min.js integrity=sha384-J08i8An/QeARD9ExYpvphB8BsyOj3Gh2TSh1aLINKO3L0cMSH2dN3E22zFoXEi0Q crossorigin=anonymous></script><script src=https://blog.glowled.top/js/main.js></script><script src=https://blog.glowled.top/js/aos.js></script><script>var aosInit=()=>{AOS.init({duration:1e3,easing:"ease",once:!0,offset:50})};document.readyState==="loading"?document.addEventListener("DOMContentLoaded",aosInit):aosInit()</script><script src=https://blog.glowled.top/js/pjax_main.js data-pjax></script><script>var ALGOLIA_CONFIG={logo:"/images/algolia_logo.svg",algolia:{applicationID:"8IR6O9D8SX",apiKey:"9b417a491dad19d1c9cc5f7ca4cf1c14",indexName:"glowled.github.io",hits:{per_page:parseInt("10")},labels:{input_placeholder:"搜索.....",hits_empty:"未发现与 「${query}」相关内容",hits_stats:"找到${hits}条结果（用时 ${time} ms）"}}}</script><script src=https://npm.webcache.cn/algoliasearch@4.17.1/dist/algoliasearch-lite.umd.js deferintegrity=sha384-xvLS0jfKuoREs7pqkRI/OI8GcqohO5S+jQz7ZBtQXnsXmD+9jDOOY4cL6dCPzlrk crossorigin=anonymous></script><script src=https://npm.webcache.cn/instantsearch.js@4.56.1/dist/instantsearch.production.min.js deferintegrity=sha384-hHJCflT4KBLQyHfKO9vpstIcFKn/Y+KHTORelMMEn7mOp2AVPp+7fr03dLgZiV3J crossorigin=anonymous></script><script src=https://blog.glowled.top/js/algolia_search.js></script><script src=https://npm.webcache.cn/theme-shokax-pjax@0.0.3/dist/index.umd.js integrity=sha384-xneY1WY8hOfUzswrE4CrYq35N4BdVcxqxwHPr9zawE/jMSCxD+jAPU55x/jj3wlf crossorigin=anonymous></script><script>function loadScripts(e,t){if(t<e.length){const n=e[t],s=n.getAttribute("src"),o=e=>new Promise((t,s)=>{const o=document.createElement("script");n.type&&(o.type=n.type),n.src&&(o.src=n.src,n.integrity&&(o.integrity=n.integrity),n.crossOrigin&&(o.crossOrigin=n.crossOrigin),o.onload=t,o.onerror=s),e&&(o.text=e),document.head.appendChild(o),n.src||t()});(s?o():o(n.text)).then(()=>loadScripts(e,t+1)).catch(n=>{console.error(`Failed to load script: ${s||"inline script"}`,n),loadScripts(e,t+1)})}}window.Pjax&&(Pjax.prototype.getElements=function(){const t=window.siteConfig.i18n_languages,a=window.siteConfig.base;let n=new URL(a).pathname;n.endsWith("/")||(n+="/");const s=window.location.href,o=new URL(s).pathname.replace(n,""),i=document.querySelectorAll("a[href]"),e=[];for(let c=0;c<i.length;c++){const a=i[c],r=a.getAttribute("href"),u=a.getAttribute("target")==="_blank"||a.getAttribute("rel")?.includes("noopener");if(u||r.startsWith("mailto:")||r.startsWith("tel:")||r.startsWith("javascript:")||r.startsWith("data:")||r.startsWith("vbscript:"))continue;if(!t){e.push(a);continue}const h=new URL(r,s).href,l=new URL(h).pathname.replace(n,"");if(!l||!o){e.push(a);continue}const d=t.findIndex(e=>o.startsWith(e.Lang));if(d>-1){const n=t.findIndex(e=>l.startsWith(e.Lang));n===d&&e.push(a)}else{const n=t.findIndex(e=>l.startsWith(e.Lang));n===-1&&e.push(a)}}return e}),window.Pjax&&new window.Pjax({selectors:["#header>img","#header>picture","head title","#header-title","#subtitle-wrap","#main","#content",".sidebar-widget",".sidebar-wrapper","#mobile-nav","#lazy-script","#i18n-nav"],switches:{"#content":function(e,t){e.className=t.className,this.onSwitch()},"#header-title":Pjax.switches.outerHTML,"#subtitle-wrap":Pjax.switches.outerHTML,"#main":function(e,t){const n=[...t.querySelectorAll("script")];loadScripts(n,0),e.outerHTML=t.outerHTML,this.onSwitch()},"#mobile-nav":Pjax.switches.outerHTML,"#lazy-script":function(e,t){const n=[...t.querySelectorAll("script")];loadScripts(n,0),e.innerHTML=t.innerHTML,this.onSwitch()}},cacheBust:!1})</script><script src=https://blog.glowled.top/js/pjax.js></script><div id=lazy-script><div><script data-pjax>window.REIMU_POST={author:"GlowLED",title:"强化学习基础-粗略过一遍",url:"https://blog.glowled.top/post/reinforcement-learning-base-quickpass/",description:"把强化学习的基础知识粗略地过了一遍，几乎无数学。但是还是不全。",cover:"https://blog.glowled.top/images/banner_yanami.jpg"}</script><script src=https://blog.glowled.top/js/insert_highlight.js data-pjax></script><script type=module data-pjax>const PhotoSwipeLightbox = (await safeImport("https:\/\/npm.webcache.cn\/photoswipe@5.4.4\/dist\/photoswipe-lightbox.esm.min.js", "sha384-DiL6M\/gG\u002bwmTxmCRZyD1zee6lIhawn5TGvED0FOh7fXcN9B0aZ9dexSF\/N6lrZi\/")).default;const pswp = () => {
          if (_$$('.article-entry a.article-gallery-item').length > 0) {
            new PhotoSwipeLightbox({
              gallery: '.article-entry',
              children: 'a.article-gallery-item',pswpModule: () => safeImport("https:\/\/npm.webcache.cn\/photoswipe@5.4.4\/dist\/photoswipe.esm.min.js", "sha384-WkkO3GCmgkC3VQWpaV8DqhKJqpzpF9JoByxDmnV8\u002boTJ7m3DfYEWX1fu1scuS4\u002bs")}).init();
          }
          if(_$$('.article-gallery a.article-gallery-item').length > 0) {
            new PhotoSwipeLightbox({
              gallery: '.article-gallery',
              children: 'a.article-gallery-item',pswpModule: () => safeImport("https:\/\/npm.webcache.cn\/photoswipe@5.4.4\/dist\/photoswipe.esm.min.js", "sha384-WkkO3GCmgkC3VQWpaV8DqhKJqpzpF9JoByxDmnV8\u002boTJ7m3DfYEWX1fu1scuS4\u002bs")}).init();
          }
          window.lightboxStatus = 'done';
          window.removeEventListener('lightbox:ready', pswp);
        }
        if(window.lightboxStatus === 'ready') {
          pswp()
        } else {
          window.addEventListener('lightbox:ready', pswp);
        }
      </script><script data-pjax>var defaultComment,savedCommentType,configDefault,loadScript=(e,t)=>{const n=document.createElement("script");return n.src=e,t&&(n.integrity=t),n.crossOrigin="anonymous",n},commentConfigKeys=["valine","waline","twikoo","gitalk","giscus"],commentConfig={valine:{enable:!1,load:()=>{const e=document.querySelector(".valine-comment");if(!e)return;e.style.display="block";const t=loadScript("https://npm.webcache.cn/valine@1.5.1/dist/Valine.min.js","webcache|valine@1.5.1/dist/Valine.min.js".startsWith("local")?0[0]:"sha384-3ma91AExDeMAZ1rjTjaP8V2A2obQE+s5ltKRwYlwdpArz9xVbp0tF3b0VV2ACNPn");t.onload=()=>{const e=["nick","mail","link"],t="nick,mail,link".split(",").filter(t=>e.indexOf(t)>-1),n=JSON.parse("true"),s=JSON.parse("true"),o=JSON.parse("false"),i=0[0];new Valine({el:".valine-comment",appId:"",appKey:"",placeholder:"Just go go",pageSize:"10",avatar:"mp",lang:document.documentElement.lang||"en",recordIP:n,highlight:s,visitor:o,requiredFields:t,path:window.location.pathname,serverURLs:i})},document.head.appendChild(t)}},waline:{enable:!1,load:async()=>{const t=document.querySelector(".waline-comment");if(!t)return;t.style.display="block";let e;const n="https://npm.webcache.cn/@waline/client@2.15.8/dist/waline.mjs";if("webcache|@waline/client@2.15.8/dist/waline.mjs".startsWith("local")){const t=await safeImport(n);e=t.init}else{const t=await safeImport(n,"sha384-9sbqJjrfGjbkI6/PI4nU/MvBfEmkkPC4YK9I4zBeMIf1CVCZdCMH/KinBEAZII/5");e=t.init}window.walineInstance=e({el:".waline-comment",serverURL:"",lang:document.documentElement.lang||"en",locale:JSON.parse("{}"),emoji:JSON.parse('["https://unpkg.com/@waline/emojis@1.2.0/weibo","https://unpkg.com/@waline/emojis@1.2.0/alus","https://unpkg.com/@waline/emojis@1.2.0/bilibili","https://unpkg.com/@waline/emojis@1.2.0/qq","https://unpkg.com/@waline/emojis@1.2.0/tieba","https://unpkg.com/@waline/emojis@1.2.0/tw-emoji"]'),meta:JSON.parse('["nick","mail","link"]'),requiredMeta:JSON.parse('["nick","mail"]'),wordLimit:0,comment:!0,pageSize:10,dark:'html[data-theme="dark"]',pageview:!0})}},twikoo:{enable:!1,load:()=>{const e=document.querySelector(".twikoo-comment");if(!e)return;e.style.display="block";const t=loadScript("https://npm.webcache.cn/twikoo@1.6.44/dist/twikoo.all.min.js","webcache|twikoo@1.6.44/dist/twikoo.all.min.js".startsWith("local")?0[0]:"sha384-kwWLC0HjeZZnVPqCJ1AncI8tsk+kQqF9TbAmCclcc9Z0hGkfgHRzeQZxmdmZhE0K");t.onload=()=>{twikoo.init({envId:"",el:".twikoo-comment",region:"",lang:document.documentElement.lang||"en"}),twikoo.getCommentsCount({envId:"",region:"",urls:["https//blog.glowled.top/post/reinforcement-learning-base-quickpass/"],includeReply:!1}).then(e=>{document.querySelector(".twikoo-comment-count").innerText=e[0].count}).catch(e=>{console.error(e)})},document.head.appendChild(t)}},gitalk:{enable:!1,load:()=>{const e=document.querySelector(".gitalk-comment");if(!e)return;e.style.display="block";const t=loadScript("https://npm.webcache.cn/gitalk@1.8.0/dist/gitalk.min.js","webcache|gitalk@1.8.0/dist/gitalk.min.js".startsWith("local")?0[0]:"sha384-kspnZUWBoSWwoJHa0hBCXYbHGbhvU/lcEH5O8eVbSDhbPwsiVUTp/aGX/z/5EuMA");t.onload=()=>{n()},document.head.appendChild(t);function n(){let e=new Gitalk({clientID:"",clientSecret:"",repo:"",owner:"",admin:JSON.parse("null"),id:location.pathname,distractionFreeMode:!1,language:document.documentElement.lang||"en"});e.render("gitalk-comment")}}},giscus:{enable:!0,load:()=>{const t=document.querySelector(".giscus-comment");if(!t)return;t.style.display="block";const n=t.querySelector('script[src*="giscus.app/client.js"]');n&&n.remove();const s=document.querySelector("iframe.giscus-frame");s&&s.remove();const e=document.createElement("script"),o=document.documentElement.getAttribute("data-theme");e.src="https://giscus.app/client.js",e.setAttribute("data-repo","GlowLED/glowled.github.io"),e.setAttribute("data-repo-id","R_kgDOPFa6bA"),e.setAttribute("data-category","General"),e.setAttribute("data-category-id","DIC_kwDOPFa6bM4CsZ9o"),e.setAttribute("data-mapping","0"),e.setAttribute("data-strict","0"),e.setAttribute("data-reactions-enabled","1"),e.setAttribute("data-emit-metadata","0"),e.setAttribute("data-input-position","top"),e.setAttribute("data-theme",o==="dark"?"dark":"light"),e.setAttribute("data-lang",document.documentElement.lang||"en"),e.setAttribute("crossorigin","anonymous"),e.async=!0,t.appendChild(e),document.body.addEventListener("light-theme-set",()=>{const e=document.querySelector("iframe.giscus-frame");if(!e)return;e.contentWindow.postMessage({giscus:{setConfig:{theme:"light"}}},"https://giscus.app")}),document.body.addEventListener("dark-theme-set",()=>{const e=document.querySelector("iframe.giscus-frame");if(!e)return;e.contentWindow.postMessage({giscus:{setConfig:{theme:"dark"}}},"https://giscus.app")})}}};commentConfig.enable=commentConfigKeys.some(e=>commentConfig[e].enable),defaultComment="",commentConfig.enable&&(savedCommentType=localStorage.getItem("commentType"),savedCommentType&&commentConfig[savedCommentType]?.enable&&(defaultComment=savedCommentType),defaultComment||(configDefault="giscus",commentConfig[configDefault]?.enable&&(defaultComment=configDefault)),defaultComment||(defaultComment=commentConfigKeys.find(e=>commentConfig[e].enable)||""));function loadComments(){if(!commentConfig.enable)return;const e={valine:!1,waline:!1,twikoo:!1,gitalk:!1,giscus:!1},s=()=>{const e=document.querySelectorAll(".comment");e.forEach(e=>{e.style.display="none"})},t=t=>{if(e[t]){document.querySelector(`.${t}-comment`).style.display="block";return}commentConfig[t]?.load(),e[t]=!0},o=e=>{const n=document.querySelectorAll(".selector-item");for(let e=0;e<n.length;e++)n[e].classList.remove("active");e.classList.add("active");const o=e.getAttribute("data-selector");s(),t(o)},n=()=>{const e=document.querySelectorAll(".selector-item");for(let t of e)t.addEventListener("click",()=>{const e=t.getAttribute("data-selector");window.localStorage.setItem("commentType",e),o(t)});if(defaultComment){const e=document.querySelector(`[data-selector="${defaultComment}"]`);if(!e)return;e.style.display="block",e.classList.add("active"),t(defaultComment)}};document.readyState==="loading"?document.addEventListener("DOMContentLoaded",n):n()}loadComments()</script><script src=https://npm.webcache.cn/katex@0.16.22/dist/katex.min.js data-pjaxintegrity=sha384-cMkvdD8LoxVzGF/RPUKAcvmm49FQ0oxwDF3BGKtDXcEc+T1b2N+teh/OJfpU0jr6 crossorigin=anonymous></script><script src=https://npm.webcache.cn/katex@0.16.22/dist/contrib/auto-render.min.js data-pjaxintegrity=sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh crossorigin=anonymous></script><script data-pjax>var renderMath=()=>{if(!window.renderMathInElement)return;window.renderMathInElement(_$("article"),{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\[",right:"\\]",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1}]})};document.readyState==="loading"?document.addEventListener("DOMContentLoaded",renderMath,{once:!0}):renderMath()</script></div></div><script data-pjax>var updateTime=_$("#post-update-time")?.innerHTML;if(updateTime){const t=new Date(updateTime),n=new Date,s=n-t,o=s/864e5,{daysago:i,message:e}=window.siteConfig.outdate;if(o>=i){let t=`This article was last updated on ${updateTime}. Please note that the content may no longer be applicable.`;if(typeof e=="string")t=e.replace(/{time}/,updateTime);else if(typeof e=="object"){const s=document.documentElement.lang,n=Object.keys(e).find(e=>e.toLowerCase()===s.toLowerCase());n&&e[n]&&(t=e[n].replace(/{time}/,updateTime))}const n=_$("#outdate-blockquote");n&&(n.querySelector("p").innerText=t,n.style.display="block")}}</script><script src=https://npm.webcache.cn/busuanzi@2.3.0/bsz.pure.mini.js asyncintegrity=sha384-0M75wtSkhjIInv4coYlaJU83+OypaRCIq2SukQVQX04eGTCBXJDuWAbJet56id+S crossorigin=anonymous></script><script>"serviceWorker"in navigator&&navigator.serviceWorker.getRegistrations().then(e=>{for(let t of e)t.unregister()})</script><script>const reimuCopyright=String.raw`
   ______     ______     __     __    __     __  __    
  /\  == \   /\  ___\   /\ \   /\ "-./  \   /\ \/\ \   
  \ \  __<   \ \  __\   \ \ \  \ \ \-./\ \  \ \ \_\ \  
   \ \_\ \_\  \ \_____\  \ \_\  \ \_\ \ \_\  \ \_____\ 
    \/_/ /_/   \/_____/   \/_/   \/_/  \/_/   \/_____/ 
                                                    
  `;console.log(String.raw`%c ${reimuCopyright}`,"color: #ff5252;"),console.log("%c Theme.Reimu %c https://github.com/D-Sketon/hugo-theme-reimu ","color: white; background: #ff5252; padding:5px 0;","padding:4px;border:1px solid #ff5252;")</script></body></html>